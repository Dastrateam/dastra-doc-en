---
description: Here you'll learn how to use the AI Systems feature.
---

# AI Systems

## Introduction

An AI system represents the use of personal data using software developed with one or more of the techniques and approaches of artificial intelligence. This use can generate results such as content, predictions, recommendations or decisions influencing the environments with which it interacts.



> The[ OECD AI System definition](https://www.oecd.org/content/dam/oecd/en/publications/reports/2024/03/explanatory-memorandum-on-the-updated-oecd-definition-of-an-ai-system_3c815e51/623da898-en.pdf) states that "An AI system is a machine-based system that, for explicit or implicit objectives, infers, from> &#x20;the input it receives, how to generate outputs such as predictions, content,> &#x20;recommendations, or decisions that can influence physical or virtual environments.> &#x20;Different AI systems vary in their levels of autonomy and adaptiveness after deployment."

This definition aims to frame and regulate the development and use of artificial intelligence to ensure that it is used in a way that is safe, ethical and respects the fundamental rights of individuals.

Please note that to use this Dastra feature, you must have subscribed to it in your subscription plan.

## The AI Governance in the world

\
They are currently multiple AI governance frameworks in the world, such as:

* **EU AI Act**
* **ISO/IEC 42001 – AI Management System**
* **NIST AI RMF (USA)**
* **China Algorithmic Regulation & Generative AI Measures**
* **PIPL (China)**
* **CPRA ADMT (California)**
* **Colorado AI Act**
* **Brazil PL 2338/2023**
* **Singapore Model AI Governance Framework**
* **OECD AI Principles**
* **UNESCO AI Ethics Recommendation**
* **Canada voluntary AI Code**
* **Japan / Korea / India AI Guidelines**

Each framework has its specificities. In the European Union, the **AI Act** categorizes for example AI systems according to their level of potential risk, ranging from minimal-risk to high-risk systems, imposing transparency obligations and strict security and data management requirements for the most critical systems.&#x20;

In addition to the AI Act, Dastra now covers most international frameworks dedicated to AI governance: Chinese regulations (Algorithmic Recommendation Regulation, Generative AI Measures), Colorado AI Act, ADMT requirements in California, as well as the main non-binding national frameworks (UK, Japan, Korea, India, Singapore) and global standards such as ISO/IEC 42001, OECD, and NIST AI RMF.

{% hint style="info" %}
Several countries (UK AI Bill, Canada AIDA, Australia, Brazil, etc.) are still finalizing their future AI laws. Even if they have not yet been adopted, their requirements are based on a common foundation that Dastra already natively covers (governance, transparency, human oversight, risk management, documentation). We are committed to quickly integrating any new legislation once it is official.
{% endhint %}

In case you are wondering which AI governance framework applies to your organization, feel free to answer this [Global AI Regulatory Eligibility Questionnaire](https://www.dastra.eu/en/audit/referential/af0d4dcd-2f0a-47be-7337-08de2357ae70).

## AI Systems in Dastra

<figure><img src="../../.gitbook/assets/Capture d&#x27;écran 2024-06-14 171006.png" alt=""><figcaption><p>Dastra AI Systems record</p></figcaption></figure>

This feature covers all the requirements of the AI Act regulations. It will enable you to draw up a list of all AI systems present within your organization. We've designed it so that every use of personal data with AI is well defined, evaluated, analyzed and documented.

You'll learn how to set up a record of AI systems and create your own repository of AI models.\
\
More information:\
\
[establishing-a-record-of-ai-systems.md](establishing-a-record-of-ai-systems.md "mention")\
\
[import-your-ai-systems.md](import-your-ai-systems.md "mention")\
\
[risk-analysis-and-business-value.md](risk-analysis-and-business-value.md "mention")

[transparency-notice.md](transparency-notice.md "mention")

[ai-models-repository.md](ai-models-repository.md "mention")

\
<br>
