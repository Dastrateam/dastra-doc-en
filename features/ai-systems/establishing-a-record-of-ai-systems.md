# Establishing a record of AI systems

To set up a record of your AI systems, you have two options:

* Either you already have a registry that you can import directly into Dastra (go to the next section: [Import your AI systems](import-your-ai-systems.md))
* Or you don't have one. In this case, you'll have to create one yourself

## Create a record of AI Systems

To add an AI system, first click on "Create a new AI system". A window will appear, in which you must enter the name of the system and assign it to an organizational unit.

Once you've entered the required information, you'll be redirected to a 10-step form. This form will enable you to give as much detail as possible about the AI system.

<figure><img src="../../.gitbook/assets/image (383).png" alt=""><figcaption></figcaption></figure>

## The 11 Steps of the AI System Form

Below are the 11 steps to complete when documenting an AI system.

***

### 1. General

Enter **basic information** about the AI system:

* **Name** of the system
* **Brief description** of its purpose and functionality

***

### 2. Responsibilities

Define your **role and responsibilities** under the European AI Act:

* **Provider**: develops and places the AI system on the market
* **Deployer**: uses the AI system within professional activities

***

### 3. AI Models

Specify the **AI model(s)** used to process data within this system.

> ℹ️ For more details, refer to the AI Models Repository.

***

### 4. Stakeholders

Identify **stakeholders involved** in implementing and managing this AI system, including their roles (e.g. Data Scientist, DPO, Product Owner).

***

### 5. Assets

Add the **assets supporting this AI system**, such as:

* Infrastructure components
* Software tools
* APIs
* Documentation resources

***

### 6. Datasets

List the **datasets associated** with this AI system. Indicate their usage among the following phases:

* **Training**: the dataset used to **train the AI model**, enabling it to learn patterns, relationships, or classifications based on historical data.
* **Validation**: a separate dataset used to **tune model parameters and prevent overfitting**. It helps assess model performance during training and guides adjustments for optimal results.
* **Testing**: another distinct dataset used to **evaluate the final performance** of the trained and validated model before deployment. It provides an unbiased measure of how the model will perform on new, unseen data.
* **Production inference**: data processed by the AI system **during actual operation**, where the trained model generates predictions, classifications, or decisions in real-world scenarios.

***

Ensure that each dataset’s **purpose, composition, and linkage to this AI system** are clearly documented for transparency and compliance purposes.

***

### 7. Data Subjects

Specify the **categories of data subjects** whose personal data is processed by the AI system (e.g. customers, employees, users).

***

### 8. Risk Analysis

Assess the **level of risk** based on:

* Types of data processed
* Processing activities
* Potential impacts on individuals’ rights and freedoms

***

### 9. Business Value

Determine a **business value score** reflecting the system’s contribution to your organization to:

* **Prioritize** high-value projects
* Align AI initiatives with strategic objectives

***

### 10. Documentation

Attach relevant **documents and information leaflets**, such as:

* User notices
* Technical guides
* Compliance assessments (e.g. DPIAs)

***

### 11. Summary

Review a **comprehensive summary** of all information entered for this AI system before final validation and registration.

***

[risk-analysis-and-business-value.md](risk-analysis-and-business-value.md "mention")\
\
[import-your-ai-systems.md](import-your-ai-systems.md "mention")

[transparency-notice.md](transparency-notice.md "mention")

[ai-models-repository.md](ai-models-repository.md "mention")
